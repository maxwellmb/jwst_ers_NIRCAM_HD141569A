{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72449ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T14:26:30.002375Z",
     "start_time": "2024-02-08T14:26:25.007006Z"
    },
    "code_folding": [
     2,
     29,
     157,
     161,
     172,
     214,
     226,
     261,
     287,
     332,
     336,
     380
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def setup_display(width=95, fontsize=18):\n",
    "    \"\"\"\n",
    "    Sets window width and markdown fontsize for the Jupyter notebook. Width is % of window.\n",
    "    \"\"\"\n",
    "    display(HTML(\"<style>.container { width:\"+str(width)+\"% !important; }</style>\"))\n",
    "    display(HTML(\"<style>.rendered_html { font-size: \"+str(fontsize)+\"px; }</style>\"))\n",
    "    return None\n",
    "\n",
    "setup_display()\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from spaceKLIP import database\n",
    "import glob\n",
    "import webbpsf\n",
    "from copy import copy, deepcopy\n",
    "from jwst.coron import imageregistration\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from scipy import ndimage\n",
    "from specutils import Spectrum1D\n",
    "import synphot\n",
    "from webbpsf_ext import image_manip\n",
    "import lmfit\n",
    "\n",
    "def quick_implot(im, clim=None, clim_perc=[1.0, 99.0], cmap=None,\n",
    "                 show_ticks=False, lims=None, ylims=None,\n",
    "                 norm=mpl.colors.Normalize, norm_kwargs={},\n",
    "                 figsize=None, panelsize=[5,5], fig_and_ax=None, extent=None,\n",
    "                 show=True, tight_layout=True, alpha=1.0,\n",
    "                 cbar=False, cbar_orientation='vertical',\n",
    "                 cbar_kwargs={}, cbar_label=None,\n",
    "                 interpolation = None, sharex=True, sharey=True,\n",
    "                 save_name=None, save_kwargs={}):\n",
    "    \"\"\"\n",
    "    Takes either a single im as \"im\", or a list/array and plots the images in the corresponding shape.\n",
    "    e.g.\n",
    "        im = [[im1,im2],\n",
    "              [im3,im4],\n",
    "              [im5,im6]]\n",
    "              \n",
    "    generates a 2 column, 3 row figure.\n",
    "    clim defines the upper and lower limits of the color stretch for the plot.\n",
    "    If clim is a string, it should contain a comma separating\n",
    "    two entries. These entries should be one of:\n",
    "    a) interpretable as a float, in which case they serve as the \n",
    "    corresponding entry in the utilized clim, b) they should contain a\n",
    "    % symbol, in which case they are used as a percentile bound;\n",
    "    e.g., clim='0, 99.9%' will yield an image with a color\n",
    "    stretch spanning [0, np.nanpercentile(im, 99.9)], or c) they\n",
    "    should contain a '*' symbol, separating either of the \n",
    "    aforementioned options, in which case they will be multiplied \n",
    "    thusly; e.g., clim='0.01*99.9%, 99.9%' would yield a plot with \n",
    "    colormapping spanning two decades (i.e., maybe appropriate for\n",
    "    a logarithmic norm): \n",
    "    [0.01*np.nanpercentile(im, 99.9), np.nanpercentile(im, 99.9)].\n",
    "    If clim is None, clim_perc is used to compute a clim instead. If\n",
    "    clim_perc contains two values, these are the lower and upper limit\n",
    "    percentiles. If only a single value, P, is given, a symmetric clim is\n",
    "    generated spanning plus and minus the P-percentile of the absolute\n",
    "    value of im (best used with a diverging/symmetric colormap, such as\n",
    "    'coolwarm'). \n",
    "    \"\"\"   \n",
    "    if isinstance(clim, str):\n",
    "        s_clim = [i.strip() for i in clim.split(',')]\n",
    "        clim = []\n",
    "        for s in s_clim:\n",
    "            if s.isdigit():\n",
    "                clim.append(float(s))\n",
    "            elif '%' in s:\n",
    "                if '*' in s:\n",
    "                    svals = []\n",
    "                    for si in s.split('*'):\n",
    "                        if '%' in si:\n",
    "                            svals.append(np.nanpercentile(im, float(si.replace('%',''))))\n",
    "                        else:\n",
    "                            svals.append(float(si))\n",
    "                    clim.append(np.prod(svals))\n",
    "                else:\n",
    "                    clim.append(np.nanpercentile(im, float(s.replace('%',''))))\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"\"\"\n",
    "                    If clim is a string, it should contain a comma separating\n",
    "                    two entries. These entries should be one of:\n",
    "                    a) interpretable as a float, in which case they serve as the \n",
    "                    corresponding entry in the utilized clim, b) they should contain a\n",
    "                    % symbol, in which case they are used as a percentile bound;\n",
    "                    e.g., clim='0, 99.9%' will yield an image with a color\n",
    "                    stretch spanning [0, np.nanpercentile(im, 99.9)], or c) they\n",
    "                    should contain a '*' symbol, separating either of the \n",
    "                    aforementioned options, in which case they will be multiplied.\n",
    "                    \"\"\")\n",
    "            \n",
    "    elif isNone(clim):\n",
    "        if np.isscalar(clim_perc) or len(clim_perc) == 1:\n",
    "            clim = symmetric_clim_percentile(im, clim_perc)\n",
    "        else:\n",
    "            clim = np.nanpercentile(np.unique(im), clim_perc)\n",
    "        \n",
    "    if isNone(ylims):\n",
    "        ylims = lims\n",
    "        \n",
    "    normalization = norm(vmin=clim[0], vmax=clim[1], **norm_kwargs)\n",
    "    imshape = np.shape(im)\n",
    "    if isNone(fig_and_ax):\n",
    "        if len(imshape) == 2:\n",
    "            nrows = ncols = 1\n",
    "        elif len(imshape) == 3:\n",
    "            nrows, ncols = 1, imshape[0]\n",
    "        elif len(imshape) == 4:\n",
    "            nrows, ncols = imshape[0], imshape[1]\n",
    "        else:\n",
    "            raise ValueError(\"Argument 'im' must be a 2, 3, or 4 dimensional array\")\n",
    "        n_ims = nrows * ncols\n",
    "        if isNone(figsize):\n",
    "            figsize = np.array([ncols,nrows])*np.asarray(panelsize)\n",
    "        fig, ax = plt.subplots(nrows, ncols, figsize=figsize, sharex=sharex, sharey=sharey)\n",
    "    else:\n",
    "        if len(imshape) == 2:\n",
    "            nrows = ncols = 1\n",
    "        elif len(imshape) == 3:\n",
    "            nrows, ncols = 1, imshape[0]\n",
    "        elif len(imshape) == 4:\n",
    "            nrows, ncols = imshape[0], imshape[1]\n",
    "        else:\n",
    "            raise ValueError(\"Argument 'im' must be a 2, 3, or 4 dimensional array\")\n",
    "        n_ims = nrows * ncols\n",
    "        fig, ax = fig_and_ax\n",
    "    if n_ims == 1:\n",
    "        ax, im = [ax], [im]\n",
    "    else:\n",
    "        im = np.asarray(im).reshape((np.prod(imshape[0:-2]), imshape[-2], imshape[-1]))\n",
    "        ax = np.asarray(ax).flatten()\n",
    "    for ax_i, im_i in zip(ax, im):\n",
    "        implot = ax_i.imshow(im_i, origin='lower', cmap=cmap, norm=normalization, extent=extent, alpha=alpha, interpolation=interpolation)\n",
    "        if not show_ticks:\n",
    "            ax_i.set(xticks=[], yticks=[])\n",
    "        ax_i.set(xlim=lims, ylim=ylims)\n",
    "    if tight_layout:\n",
    "        fig.tight_layout()\n",
    "    if cbar:\n",
    "        cbar = fig.colorbar(implot, ax=ax, orientation=cbar_orientation, **cbar_kwargs)\n",
    "        cbar.set_label(cbar_label)\n",
    "    if not isNone(save_name):\n",
    "        plt.savefig(save_name, bbox_inches='tight', **save_kwargs)\n",
    "    if show:\n",
    "        plt.show()\n",
    "        return None\n",
    "    if n_ims == 1:\n",
    "        ax = ax[0]\n",
    "    return fig, ax\n",
    "\n",
    "def symmetric_clim_percentile(arr, clim_perc=98):\n",
    "    clim0 = np.nanpercentile(np.abs(np.unique(arr)), clim_perc)\n",
    "    return np.array([-1, 1])*clim0\n",
    "\n",
    "def isNone(arg):\n",
    "    \"\"\"\n",
    "    Just a quick convenience/shorthand function.\n",
    "    \"if isNone(x)\" works for any x, whereas \"if x == None\"\n",
    "    will sometimes cause a crash (e.g., if x is a numpy array).\n",
    "    \"\"\"\n",
    "    return isinstance(arg, type(None))\n",
    "\n",
    "\n",
    "# Convenience functions for generating model PSF images:\n",
    "\n",
    "\n",
    "def get_webbpsf_model_for_stellocentric_offset(xy, inst, spectrum=None, return_oversample=True, fov_pixels=None, osamp=None,\n",
    "                                               center_psf=True, psf_shift=None):\n",
    "    \"\"\"\n",
    "    Returns a centered WebbPSF PSF model image for a source that is offset from the coronagraph center by (xy) in arcsec \n",
    "    (where a source above the coronagraph and to the right on the detector would have positive y and x respectively)\n",
    "    \"\"\"\n",
    "    \n",
    "    siaf_ap = inst.siaf[inst.aperturename]\n",
    "    \n",
    "    options = deepcopy(inst.options) # Save options so we can return the inst object as it was.\n",
    "    \n",
    "    inst.detector_position = (siaf_ap.XSciRef + xy[0]/siaf_ap.XSciScale, siaf_ap.YSciRef + xy[1]/siaf_ap.YSciScale)\n",
    "    inst.options['coron_shift_x'] = -xy[0]\n",
    "    inst.options['coron_shift_y'] = -xy[1]\n",
    "    \n",
    "    ind_out = 2 if return_oversample else 3\n",
    "    psf_hdul = inst.calc_psf(source=spectrum, fov_pixels=fov_pixels, oversample=osamp)\n",
    "    \n",
    "    # Set inst back as it was.\n",
    "    inst.options = options\n",
    "    inst.detector_position = (siaf_ap.XSciRef, siaf_ap.YSciRef)\n",
    "    \n",
    "    if options.get('add_ipc', True) and return_oversample and \"Applied detector interpixel capacitance (IPC) model\" not in psf_hdul[ind_out].header['history']:\n",
    "        # Last condition above is to future proof in case WebbPSF starts applying IPC to the osamp extension too.\n",
    "        psf_hdul = webbpsf.detectors.apply_detector_ipc(psf_hdul, extname='OVERDIST')\n",
    "    psf = psf_hdul[ind_out].data\n",
    "    if isNone(osamp):\n",
    "        osamp = psf_hdul[ind_out].header['OVERSAMP']\n",
    "        \n",
    "    if center_psf:\n",
    "        if isNone(psf_shift): # Then we need to determine the requisite shift\n",
    "            if isNone(inst.image_mask):\n",
    "                psf_off = psf\n",
    "            else:\n",
    "                inst_off = deepcopy(inst)\n",
    "                inst_off.image_mask = None\n",
    "                psf_off = inst_off.calc_psf(source=spectrum, oversample=osamp, fov_pixels=fov_pixels)[ind_out].data\n",
    "            psf_shift = get_webbpsf_model_center_offset(psf_off, osamp)\n",
    "        psf = imageregistration.fourier_imshift(psf, psf_shift*osamp)\n",
    "    return psf\n",
    "\n",
    "\n",
    "def get_webbpsf_model_center_offset(psf_off, osamp):\n",
    "    \"\"\"\n",
    "    Returns the detector-sampled shift required to geometrically center psf_off\n",
    "    \"\"\"\n",
    "    psf_gauss = Gaussian2DKernel(x_stddev=1*osamp, y_stddev=2*osamp).array\n",
    "    psf_gauss *= psf_off.max() / psf_gauss.max()\n",
    "    psf_crop = pad_or_crop_image(psf_off, psf_gauss.shape, cval0=0)\n",
    "    psf_reg_result = imageregistration.align_array(psf_gauss, psf_crop)\n",
    "    shift = -psf_reg_result[1][:-1]/osamp\n",
    "    return shift\n",
    "\n",
    "\n",
    "def pad_or_crop_image(im, new_size, cent=None, new_cent=None, cval0=np.nan, nan_prop_threshold=0., zero_prop_threshold=0., prefilter=True):\n",
    "    new_size = np.asarray(new_size)\n",
    "    im_size = np.array(im.shape)\n",
    "    ny, nx = im_size\n",
    "    if isNone(cent):\n",
    "        cent = (np.array([nx,ny])-1.)/2.\n",
    "        \n",
    "    if isNone(new_cent):\n",
    "        new_cent = (np.array([new_size[1],new_size[0]])-1.)/2.\n",
    "        \n",
    "    if np.all([new_size == im_size, cent == new_cent]):\n",
    "        return im.copy()\n",
    "    \n",
    "    if np.all([float(i).is_integer() for i in [*cent, *new_cent]]):\n",
    "        # No need to treat nans/zeros differently if both centers are integers.\n",
    "        out_im = pad_or_crop_about_pos(im, cent, new_size, new_cent=new_cent, cval=cval0, prefilter=False, order=0)\n",
    "        \n",
    "    else:    \n",
    "        nans = np.isnan(im)\n",
    "        zeros = im == 0.\n",
    "        any_zeros = np.any(zeros)\n",
    "        any_nans = np.any(nans)\n",
    "        if any_nans:\n",
    "            out_im = pad_or_crop_about_pos(np.where(nans, 0., im), cent, new_size, new_cent=new_cent, cval=cval0, prefilter=prefilter)\n",
    "        else:\n",
    "            out_im = pad_or_crop_about_pos(im, cent, new_size, new_cent=new_cent, cval=cval0, prefilter=prefilter)\n",
    "        if any_zeros:\n",
    "            out_zeros = pad_or_crop_about_pos(zeros.astype(float), cent, new_size, new_cent=new_cent, prefilter=False)\n",
    "            out_im = np.where(out_zeros>zero_prop_threshold, 0., out_im)\n",
    "        if any_nans:\n",
    "            out_nans = pad_or_crop_about_pos(nans.astype(float), cent, new_size, new_cent=new_cent, prefilter=False)\n",
    "            out_im = np.where(out_nans>nan_prop_threshold, np.nan, out_im)\n",
    "    return out_im\n",
    "\n",
    "\n",
    "def pad_or_crop_about_pos(im, pos, new_size, new_cent=None, cval=np.nan, order=3, mode='constant', prefilter=True):\n",
    "    ny, nx = im.shape[-2:]\n",
    "    ny_new, nx_new = new_size\n",
    "    if isNone(new_cent):\n",
    "        new_cent = (np.array([nx_new,ny_new])-1.)/2.\n",
    "        \n",
    "    nd = np.ndim(im)\n",
    "    xg, yg = np.meshgrid(np.arange(nx_new, dtype=np.float64), np.arange(ny_new, dtype=np.float64))\n",
    "    \n",
    "    xg -= (new_cent[0]-pos[0])\n",
    "    yg -= (new_cent[1]-pos[1])\n",
    "    if nd == 2:\n",
    "        im_out = ndimage.map_coordinates(im, np.array([yg, xg]), order=order, mode=mode, cval=cval, prefilter=prefilter)\n",
    "    else:\n",
    "        nI = np.prod(im.shape[:-2])\n",
    "        im_reshaped = im.reshape((nI, ny, nx))\n",
    "        im_out = np.zeros((nI, ny, nx), dtype=im.dtype)\n",
    "        for i in range(nI):\n",
    "            im_out[i] = ndimage.map_coordinates(im_reshaped[i], np.array([yg, xg]), order=order, mode=mode, cval=cval, prefilter=prefilter)\n",
    "        im_out = im_out.reshape((*im.shape[:-2], ny, nx))\n",
    "    return im_out\n",
    "\n",
    "\n",
    "# Functions to use during optimization\n",
    "\n",
    "\n",
    "def c_to_c_osamp(c, osamp):\n",
    "    return np.asarray(c)*osamp + 0.5*(osamp-1)\n",
    "\n",
    "\n",
    "def model_rescale_factor(A, B, sig=None, mask=None):\n",
    "    \"\"\"\n",
    "    Determines the value of scalar c such that:\n",
    "        chi^2 = sum [ (A-c*B)^2 / sig^2 ]\n",
    "    is minimized.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        Array of measurements\n",
    "    B : numpy.ndarray\n",
    "        Array of model values. Shape must match A and B\n",
    "    sig : numpy.ndarray, optional\n",
    "        The 1 sigma uncertainty for the measurements of A.\n",
    "    mask : numpy.ndarray, optional\n",
    "        A boolean mask with False for entries of A, B, and sig not to be\n",
    "        utilized, and True for entries that are. Defaults to None.\n",
    "    Returns\n",
    "    -------\n",
    "    c : float\n",
    "        The scaling factor to multiply the model (B) by to achieve the minimum chi^2\n",
    "        for measurements (A) having the given uncertainties (sig).\n",
    "    \"\"\"\n",
    "    if np.shape(A) != np.shape(B):\n",
    "        raise ValueError(\"A and B must be arrays of the same shape!\")\n",
    "    if not isNone(sig):\n",
    "        if np.shape(A) != np.shape(sig):\n",
    "            raise ValueError(\"A, B, and sig must be arrays of the same shape if sig is specified!\")\n",
    "    else:\n",
    "        sig = 1\n",
    "    if isNone(mask):\n",
    "        c = np.nansum(A * B / (sig ** 2)) / np.nansum((B ** 2) / (sig ** 2))\n",
    "    elif np.shape(mask)[-2:] != np.shape(A)[-2:]:\n",
    "        raise ValueError(\"If provided, mask's shape must match the final axes of A, B, and sig!\")\n",
    "    else:\n",
    "        Amsk, Bmsk = A[..., mask], B[..., mask]\n",
    "        if np.ndim(sig) != 0:\n",
    "            Smsk = sig[..., mask]\n",
    "        else:\n",
    "            Smsk = sig\n",
    "        c = np.nansum(Amsk * Bmsk / (Smsk ** 2)) / np.nansum((Bmsk ** 2) / (Smsk ** 2))\n",
    "    return c\n",
    "\n",
    "\n",
    "def dist_to_pt(pt, nx=201, ny=201, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Returns a distance array of size (ny,nx), \n",
    "    where each pixel corresponds to the euclidean \n",
    "    distance of that pixel from pt=(x,y).\n",
    "    \"\"\"\n",
    "    xaxis = np.arange(0, nx, dtype=dtype)-pt[0]\n",
    "    yaxis = np.arange(0, ny, dtype=dtype)-pt[1]\n",
    "    return np.sqrt(xaxis**2 + yaxis[:, np.newaxis]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5c56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T14:26:33.168090Z",
     "start_time": "2024-02-08T14:26:33.127888Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up a source spectrum (for the reference star) to pass to WebbPSF however you prefer (likely minimal impact either way)\n",
    "# Note: only the shape matters, as we're rescaling the brightness to minimize residuals with the data anyway.\n",
    "\n",
    "specfile = 'bt-nextgen_teff_4800_logg_4.0_feh_0.0_spec.dat'\n",
    "swave, sflux = np.loadtxt(specfile).T\n",
    "spec1d = Spectrum1D(spectral_axis=(swave*u.micron), flux=sflux*(u.Watt / u.m**2 / u.micron))\n",
    "spectrum = synphot.spectrum.SourceSpectrum.from_spectrum1d(spec1d)\n",
    "spectrum.meta['name'] = 'source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a46a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T14:21:36.815986Z",
     "start_time": "2024-02-08T14:21:36.626501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to directory containing the fits files to use.\n",
    "wdir = '/Users/kdlawso1/jwst/hd141569a/nircam/new_data_231108/stage2/'\n",
    "\n",
    "fitsfiles = np.sort(glob.glob(wdir+'*_calints.fits'))\n",
    "\n",
    "# Make a spaceklip database for these files\n",
    "Database = database.Database(wdir)\n",
    "Database.read_jwst_s012_data(datapaths=fitsfiles,\n",
    "                             psflibpaths=None,\n",
    "                             bgpaths=None)\n",
    "\n",
    "print('\\nConcatenations:\\n')\n",
    "\n",
    "for key in Database.obs:\n",
    "    display(Database.obs[key])\n",
    "\n",
    "print('\\nKeys:\\n')\n",
    "print(list(Database.obs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23f087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T19:22:27.762982Z",
     "start_time": "2024-02-06T19:22:25.252285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set which concatenation to work with and proceed\n",
    "concats = list(Database.obs.keys())\n",
    "\n",
    "concat_key = concats[0]\n",
    "db_tab = Database.obs[concat_key]\n",
    "\n",
    "expmask = db_tab['TYPE'] == 'REF'\n",
    "\n",
    "expfiles = db_tab['FITSFILE'][expmask]\n",
    "\n",
    "h0, h1 = fits.getheader(expfiles[0]), fits.getheader(expfiles[0], ext=1)\n",
    "\n",
    "imcube = []\n",
    "errcube = []\n",
    "for i,f in enumerate(expfiles):\n",
    "    imints, errints = fits.getdata(f, ext=1), fits.getdata(f, ext=2)\n",
    "    n = np.sum(np.isfinite(imints), axis=0)\n",
    "    sig_med_over_sig_mean = np.sqrt(np.pi*(2*n+1)/(4*n))\n",
    "    sig_mean = np.sqrt(np.nansum(errints**2, axis=0))/n\n",
    "    err_im_med = sig_mean * sig_med_over_sig_mean\n",
    "    im_med = np.nanmedian(imints, axis=0)\n",
    "    imcube.append(im_med)\n",
    "    errcube.append(err_im_med)\n",
    "    \n",
    "imcube = np.asarray(imcube)\n",
    "errcube = np.asarray(errcube)\n",
    "\n",
    "filt = db_tab[expmask]['FILTER'][0] \n",
    "pxscale = db_tab[expmask]['PIXSCALE'][0]*u.arcsec/u.pixel\n",
    "\n",
    "lam = db_tab[expmask]['CWAVEL'][0]\n",
    "d_eff = 5.2*u.meter\n",
    "fwhm = ((np.rad2deg(lam/(d_eff.to(u.micron).value))*u.deg).to(u.arcsec)/pxscale).value # pixels\n",
    "\n",
    "dithers = np.asarray([db_tab[expmask]['XOFFSET'], db_tab[expmask]['YOFFSET']]).T\n",
    "\n",
    "db_tab[expmask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077dabd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T19:36:35.895575Z",
     "start_time": "2024-02-06T19:36:25.949857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the WebbPSF instrument object and pre-compute the PSF center offset to save time during optimization\n",
    "inst = webbpsf.setup_sim_to_match_file(expfiles[0])\n",
    "\n",
    "inst.options['coron_shift_x'] = 0.\n",
    "inst.options['coron_shift_y'] = 0.\n",
    "\n",
    "if 'S_IPC' in h0 and h0['S_IPC'] == 'COMPLETE':\n",
    "    inst.options['add_ipc'] = False\n",
    "\n",
    "# Compute synthetic PSF center offset and plot to verify\n",
    "inst_off = deepcopy(inst)\n",
    "inst_off.image_mask = None\n",
    "psf_off = inst_off.calc_psf(source=None, oversample=4, fov_pixels=35)[2].data\n",
    "psf_shift = get_webbpsf_model_center_offset(psf_off, osamp=4)\n",
    "\n",
    "import json\n",
    "import spaceKLIP\n",
    "\n",
    "with open(spaceKLIP.__path__[0]+'/resources/crpix_jarron.json', 'r') as file:\n",
    "    crpix_jarron = json.load(file)\n",
    "    \n",
    "with open(spaceKLIP.__path__[0]+'/resources/filter_shifts_jarron.json', 'r') as file:\n",
    "    filt_offsets = json.load(file)\n",
    "    \n",
    "c_coron_ta = np.array(crpix_jarron[inst.aperturename])-1 # Coronagraph position for the TA filter\n",
    "\n",
    "c_coron = c_coron_ta + np.array(filt_offsets[filt]) # Coronagraph position adjusted for filter dependent offset\n",
    "\n",
    "c = (np.array(psf_off.shape[::-1])-1.)/2.\n",
    "\n",
    "fig,axes = quick_implot([psf_off, imageregistration.fourier_imshift(psf_off, psf_shift*4)], show=False, clim_perc=[1,99.995])\n",
    "\n",
    "labels = ['Not Centered', 'Centered']\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.scatter(*c, marker='+', c='red', s=150)\n",
    "    ax.set_title(labels[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408475df",
   "metadata": {},
   "source": [
    "Next, we define our objective function:\n",
    "\n",
    "- takes an LMFit Parameters object, as well as necessary arguments and keyword arguments\n",
    "\n",
    "\n",
    "- generates the corresponding model\n",
    "\n",
    "\n",
    "- returns the uncertainty weighted residuals between the model and data (or returns the model itself if return_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba105bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T18:22:29.254605Z",
     "start_time": "2024-02-07T18:22:29.244576Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def webbpsf_model_objective(p, imcube, dithers, inst, fov_pix, spectrum, c_coron, mask, sig=None, osamp=2, return_model=False, psf_shift=None):\n",
    "    if isNone(psf_shift):\n",
    "        psf_shift = 0.\n",
    "        \n",
    "    siaf_ap = inst.siaf[inst.aperturename]\n",
    "    \n",
    "    inst_opt = deepcopy(inst)\n",
    "    inst_opt.options['pupil_shift_x'] = p['xshear'].value\n",
    "    inst_opt.options['pupil_shift_y'] = p['yshear'].value\n",
    "    inst_opt.options['defocus_waves'] = p['defocus'].value\n",
    "    inst_opt.options['pupil_rotation'] = p['pupil_rotation'].value\n",
    "    \n",
    "    xy0 = np.array([p['xsourceoffset'].value, p['ysourceoffset'].value])\n",
    "\n",
    "    nI, ny, nx = imcube.shape\n",
    "    \n",
    "    modelcube = np.zeros_like(imcube)\n",
    "    for i in range(nI):\n",
    "        xy = xy0 + dithers[i]\n",
    "        psf0 = get_webbpsf_model_for_stellocentric_offset(xy, inst_opt, spectrum=spectrum, \n",
    "                                                          return_oversample=True,\n",
    "                                                          fov_pixels=fov_pix, osamp=osamp,\n",
    "                                                          center_psf=False) # To minimize interpolations: center_psf=False, then apply center shift when padding below.\n",
    "\n",
    "        xy_px = c_coron + xy/np.array([siaf_ap.XSciScale, siaf_ap.YSciScale])\n",
    "    \n",
    "        psf_osamp = pad_or_crop_image(psf0, new_size=np.array([ny,nx])*osamp, new_cent=c_to_c_osamp(xy_px+psf_shift, osamp), cval0=0.,\n",
    "                                      nan_prop_threshold=1e-8, zero_prop_threshold=1e-8)\n",
    "        \n",
    "        modelcube[i] = image_manip.frebin(psf_osamp, scale=1./osamp)\n",
    "    \n",
    "    modelcube *= model_rescale_factor(imcube, modelcube, mask=mask, sig=sig)\n",
    "    \n",
    "    if return_model:\n",
    "        return modelcube\n",
    "    \n",
    "    global counter\n",
    "    counter += 1\n",
    "    print('Models evaluated: {0: <16}'.format(counter), end='\\r')\n",
    "    \n",
    "    if isNone(sig):\n",
    "        sig = np.ones_like(imcube)\n",
    "    \n",
    "    res = ((imcube - np.nan_to_num(modelcube))/sig)[..., mask]\n",
    "    \n",
    "    return np.abs(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f234a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T19:39:44.927149Z",
     "start_time": "2024-02-06T19:39:43.653791Z"
    }
   },
   "outputs": [],
   "source": [
    "# First: fit stellar offset\n",
    "\n",
    "# Initialize an LMFit parameter object for optimization.\n",
    "p = lmfit.Parameters()\n",
    "\n",
    "# Arguments for each param added are (respectively): \n",
    "# the parameter name, the initial value, min allowed value, max allowed value, and whether or not it will be varied.\n",
    "p.add('defocus', value=0.0, min=-0.4, max=0.4, vary=True) # setting for inst.options['defocus_waves']\n",
    "p.add('xshear', value=0.0, min=-0.05, max=0.05, vary=True) # setting for inst.options['pupil_shift_x']\n",
    "p.add('yshear', value=0.0, min=-0.05, max=0.05, vary=True) # setting for inst.options['pupil_shift_y']\n",
    "p.add('pupil_rotation', value=0., min=-5., max=5., vary=True) # setting for inst.options['pupil_rotation']\n",
    "\n",
    "# Offset of the source center from the coronagraph center ***in arcsec*** for the center of dither pattern\n",
    "# In other words: the offset of the source relative to the coronagraph center if dither == [0,0]\n",
    "p.add('xsourceoffset', value=0.)\n",
    "p.add('ysourceoffset', value=0.)\n",
    "# Note: we assume that the dither movement is perfect. I.e., we just fit for one coronagraph offset rather than one per dither position\n",
    "\n",
    "rmap = dist_to_pt(c_coron, imcube.shape[2], imcube.shape[1])\n",
    "rmax = 40*fwhm # Max distance from the coronagraph center to consider in our goodness of fit calculation (should only matter if other sources are present in the data)\n",
    "# Generate a boolean mask that is True wherever we want to consider in our goodness of fit for each iteration.\n",
    "mask = (rmap < rmax) & np.all(np.isfinite(imcube), axis=0)\n",
    "\n",
    "fov_pix = np.ceil(rmax*2+5) # Adding a few pixels beyond the mask region to be safe with interpolation.\n",
    "\n",
    "sig = errcube\n",
    "\n",
    "modelcube0 = webbpsf_model_objective(p, imcube, dithers, inst, fov_pix, spectrum, c_coron, mask, sig=sig, return_model=True, psf_shift=psf_shift)\n",
    "\n",
    "xysourceoffsets = []\n",
    "for i in range(len(dithers)):\n",
    "    regres = imageregistration.align_array(np.nan_to_num(imcube[i]), modelcube0[[i]], mask=mask)\n",
    "    xysourceoffset = -(regres[1][0, :-1]*u.pix * pxscale).value\n",
    "    xysourceoffsets.append(xysourceoffset)\n",
    "    \n",
    "xysourceoffsets = np.array(xysourceoffsets)\n",
    "xysourceoffset = np.nanmedian(xysourceoffsets, axis=0)\n",
    "\n",
    "p.add('xsourceoffset', value=xysourceoffset[0], vary=False)\n",
    "p.add('ysourceoffset', value=xysourceoffset[1], vary=False)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edab60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T20:37:39.017762Z",
     "start_time": "2024-02-06T19:41:38.332517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now: optimize considering only PSF wings and varying only pupil_rotation:\n",
    "\n",
    "mask = (rmap < rmax) & (rmap > 20*fwhm) & np.all(np.isfinite(imcube), axis=0)\n",
    "\n",
    "# 'counter' is just used to make print statements to reassure you that the code isn't hung up.\n",
    "counter = 0\n",
    "\n",
    "p['defocus'].vary = False\n",
    "p['xshear'].vary = False\n",
    "p['yshear'].vary = False\n",
    "\n",
    "quick_implot(np.where(mask, imcube[0], np.nan))\n",
    "# Run the optimization procedure using the Powell method. See lmfit documentation for other options\n",
    "res = lmfit.minimize(webbpsf_model_objective, p, method='powell',\n",
    "                     args=(imcube, dithers, inst, fov_pix, spectrum, c_coron, mask),\n",
    "                     kws=dict(sig=sig, osamp=2, psf_shift=psf_shift))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec89a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:59:34.475740Z",
     "start_time": "2024-02-06T20:37:39.019444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now adopt best-fit pupil rotation and optimize defocus and shear (could also let the offsets vary to be safe):\n",
    "\n",
    "p.add('pupil_rotation', value=res.params['pupil_rotation'].value, vary=False)\n",
    "\n",
    "p['defocus'].vary = True\n",
    "p['xshear'].vary = True\n",
    "p['yshear'].vary = True\n",
    "\n",
    "mask = (rmap < rmax) & np.all(np.isfinite(imcube), axis=0)\n",
    "\n",
    "# 'counter' is just used to make print statements to reassure you that the code isn't hung up.\n",
    "counter = 0\n",
    "\n",
    "quick_implot(np.where(mask, imcube[0], np.nan))\n",
    "\n",
    "# Run the optimization procedure using the Powell method. See lmfit documentation for other options\n",
    "res = lmfit.minimize(webbpsf_model_objective, p, method='powell',\n",
    "                     args=(imcube, dithers, inst, fov_pix, spectrum, c_coron, mask),\n",
    "                     kws=dict(sig=sig, osamp=2, psf_shift=psf_shift))\n",
    "\n",
    "# Re-generate the final best-fit model for inspection\n",
    "modelcube = webbpsf_model_objective(res.params, imcube, dithers, inst, 351, spectrum, c_coron, mask, sig=sig, osamp=2, return_model=True, psf_shift=psf_shift)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd74c67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:38:52.225086Z",
     "start_time": "2024-02-07T16:38:46.658522Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the data vs the model for all 9 dithers\n",
    "\n",
    "w = rmax\n",
    "\n",
    "pim = np.where(mask, np.array([imcube/errcube, modelcube/errcube, (imcube-modelcube)/errcube]).transpose((1,0,2,3)), np.nan)\n",
    "\n",
    "fig,axes = quick_implot(pim, lims=c_coron[[0]]+[-w,w], ylims=c_coron[[1]]+[-w,w],\n",
    "                        cmap='coolwarm', clim_perc=99.9, show_ticks=True, show=False)\n",
    "\n",
    "axes[0].set_title('Data')\n",
    "axes[1].set_title('Model')\n",
    "axes[2].set_title('Residuals')\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.grid(c='k', alpha=0.25)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131dba7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T18:57:27.743866Z",
     "start_time": "2024-02-07T18:57:27.726366Z"
    }
   },
   "outputs": [],
   "source": [
    "pnames = list(res.params.keys())[:-2]\n",
    "pvals = np.array([res.params[key].value for key in pnames])\n",
    "\n",
    "f_out = '{}JWST_{}_{}_{}_{}_{}_{}_WebbPSF_params.txt'.format(Database.output_dir, h0['INSTRUME'], h0['DETECTOR'], h0['filter'], h0['pupil'], h0['coronmsk'], h0['SUBARRAY'])\n",
    "np.savetxt(f_out, pvals[np.newaxis], header=' '.join(pnames), fmt='%.5f')\n",
    "\n",
    "print(f'Output written to:\\n{f_out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7beaf0",
   "metadata": {},
   "source": [
    "# Now load the F360M data and fit the defocus, keeping all other parameters the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725fa01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T18:58:31.335920Z",
     "start_time": "2024-02-07T18:58:29.988837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set which concatenation to work with and proceed\n",
    "concats = list(Database.obs.keys())\n",
    "\n",
    "concat_key = concats[1]\n",
    "db_tab = Database.obs[concat_key]\n",
    "\n",
    "expmask = db_tab['TYPE'] == 'REF'\n",
    "\n",
    "expfiles = db_tab['FITSFILE'][expmask]\n",
    "\n",
    "h0, h1 = fits.getheader(expfiles[0]), fits.getheader(expfiles[0], ext=1)\n",
    "\n",
    "imcube = []\n",
    "errcube = []\n",
    "for i,f in enumerate(expfiles):\n",
    "    imints, errints = fits.getdata(f, ext=1), fits.getdata(f, ext=2)\n",
    "    n = np.sum(np.isfinite(imints), axis=0)\n",
    "    sig_med_over_sig_mean = np.sqrt(np.pi*(2*n+1)/(4*n))\n",
    "    sig_mean = np.sqrt(np.nansum(errints**2, axis=0))/n\n",
    "    err_im_med = sig_mean * sig_med_over_sig_mean\n",
    "    im_med = np.nanmedian(imints, axis=0)\n",
    "    imcube.append(im_med)\n",
    "    errcube.append(err_im_med)\n",
    "    \n",
    "imcube = np.asarray(imcube)\n",
    "errcube = np.asarray(errcube)\n",
    "\n",
    "filt = db_tab[expmask]['FILTER'][0] \n",
    "pxscale = db_tab[expmask]['PIXSCALE'][0]*u.arcsec/u.pixel\n",
    "\n",
    "lam = db_tab[expmask]['CWAVEL'][0]\n",
    "d_eff = 5.2*u.meter\n",
    "fwhm = ((np.rad2deg(lam/(d_eff.to(u.micron).value))*u.deg).to(u.arcsec)/pxscale).value # pixels\n",
    "\n",
    "dithers = np.asarray([db_tab[expmask]['XOFFSET'], db_tab[expmask]['YOFFSET']]).T\n",
    "\n",
    "db_tab[expmask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbad728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T19:02:03.814405Z",
     "start_time": "2024-02-07T19:01:55.513101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the WebbPSF instrument object and pre-compute the PSF center offset to save time during optimization\n",
    "inst = webbpsf.setup_sim_to_match_file(expfiles[0])\n",
    "\n",
    "inst.options['coron_shift_x'] = 0.\n",
    "inst.options['coron_shift_y'] = 0.\n",
    "\n",
    "if 'S_IPC' in h0 and h0['S_IPC'] == 'COMPLETE':\n",
    "    inst.options['add_ipc'] = False\n",
    "\n",
    "# Compute PSF center offset and plot for sanity\n",
    "inst_off = deepcopy(inst)\n",
    "inst_off.image_mask = None\n",
    "psf_off = inst_off.calc_psf(source=None, oversample=4, fov_pixels=35)[2].data\n",
    "psf_shift = get_webbpsf_model_center_offset(psf_off, osamp=4)\n",
    "\n",
    "import json\n",
    "import spaceKLIP\n",
    "\n",
    "with open(spaceKLIP.__path__[0]+'/resources/crpix_jarron.json', 'r') as file:\n",
    "    crpix_jarron = json.load(file)\n",
    "    \n",
    "with open(spaceKLIP.__path__[0]+'/resources/filter_shifts_jarron.json', 'r') as file:\n",
    "    filt_offsets = json.load(file)\n",
    "    \n",
    "c_coron_ta = np.array(crpix_jarron[inst.aperturename])-1\n",
    "\n",
    "c_coron = c_coron_ta + np.array(filt_offsets[filt])\n",
    "\n",
    "c = (np.array(psf_off.shape[::-1])-1.)/2.\n",
    "\n",
    "fig,axes = quick_implot([psf_off, imageregistration.fourier_imshift(psf_off, psf_shift*4)], show=False, clim_perc=[1,99.995])\n",
    "\n",
    "labels = ['Not Centered', 'Centered']\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.scatter(*c, marker='+', c='red', s=150)\n",
    "    ax.set_title(labels[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f215e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T20:12:28.816438Z",
     "start_time": "2024-02-07T19:06:03.938647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting defocus only (should be much faster)\n",
    "p = deepcopy(res.params)\n",
    "for key in p.keys():\n",
    "    p[key].vary=False\n",
    "\n",
    "p['defocus'].value=0.\n",
    "p['defocus'].vary=True\n",
    "\n",
    "rmap = dist_to_pt(c_coron, imcube.shape[2], imcube.shape[1])\n",
    "rmax = 40*fwhm # Max distance from the coronagraph center to consider in our goodness of fit calculation (should only matter if other sources are present in the data)\n",
    "\n",
    "# Generate a boolean mask that is True wherever we want to consider in our goodness of fit for each iteration.\n",
    "mask = (rmap < rmax) & np.all(np.isfinite(imcube), axis=0)\n",
    "\n",
    "fov_pix = np.ceil(rmax*2+5) # Adding a few pixels beyond the mask region to be safe with interpolation.\n",
    "\n",
    "sig = errcube\n",
    "\n",
    "mask = (rmap < rmax) & np.all(np.isfinite(imcube), axis=0)\n",
    "\n",
    "# 'counter' is just used to make print statements to reassure you that the code isn't hung up.\n",
    "counter = 0\n",
    "\n",
    "quick_implot(np.where(mask, imcube[0], np.nan))\n",
    "\n",
    "# Run the optimization procedure using the Powell method. See lmfit documentation for other options\n",
    "res2 = lmfit.minimize(webbpsf_model_objective, p, method='powell',\n",
    "                     args=(imcube, dithers, inst, fov_pix, spectrum, c_coron, mask),\n",
    "                     kws=dict(sig=sig, osamp=2, psf_shift=psf_shift))\n",
    "\n",
    "modelcube = webbpsf_model_objective(res2.params, imcube, dithers, inst, 351, spectrum, c_coron, mask, sig=sig, osamp=2, return_model=True, psf_shift=psf_shift)\n",
    "\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78160a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T20:12:35.019595Z",
     "start_time": "2024-02-07T20:12:28.818124Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = rmax\n",
    "\n",
    "pim = np.where(mask, np.array([imcube/errcube, modelcube/errcube, (imcube-modelcube)/errcube]).transpose((1,0,2,3)), np.nan)\n",
    "\n",
    "fig,axes = quick_implot(pim, lims=c_coron[[0]]+[-w,w], ylims=c_coron[[1]]+[-w,w],\n",
    "                        cmap='coolwarm', clim_perc=99.9, show_ticks=True, show=False)\n",
    "\n",
    "axes[0].set_title('Data')\n",
    "axes[1].set_title('Model')\n",
    "axes[2].set_title('Residuals')\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.grid(c='k', alpha=0.25)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacdea38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T20:22:21.568324Z",
     "start_time": "2024-02-07T20:22:21.549035Z"
    }
   },
   "outputs": [],
   "source": [
    "pnames = list(res2.params.keys())[:-2]\n",
    "pvals = np.array([res2.params[key].value for key in pnames])\n",
    "\n",
    "f_out = '{}JWST_{}_{}_{}_{}_{}_{}_WebbPSF_params.txt'.format(Database.output_dir, h0['INSTRUME'], h0['DETECTOR'], h0['filter'], h0['pupil'], h0['coronmsk'], h0['SUBARRAY'])\n",
    "\n",
    "np.savetxt(f_out, pvals[np.newaxis], header=' '.join(pnames), fmt='%.5f')\n",
    "\n",
    "print(f'Output written to:\\n{f_out}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
